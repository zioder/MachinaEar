import pandas as pd
from feast import FeatureStore
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FeastFeatureManager:
    """
    Gestionnaire pour les op√©rations Feast
    """
    
    def __init__(self, repo_path: str = "./feast_config"):
        """
        Initialise le gestionnaire Feast
        
        Args:
            repo_path: Chemin vers le dossier contenant feature_store.yaml
        """
        self.store = FeatureStore(repo_path=repo_path)
        
    def materialize_features(self, start_date: datetime, end_date: datetime):
        """
        Mat√©rialise les features dans le online store
        
        Args:
            start_date: Date de d√©but
            end_date: Date de fin
        """
        try:
            logger.info(f"Mat√©rialisation des features de {start_date} √† {end_date}...")
            self.store.materialize(start_date=start_date, end_date=end_date)
            logger.info("‚úì Mat√©rialisation termin√©e avec succ√®s")
        except Exception as e:
            logger.error(f"Erreur lors de la mat√©rialisation: {e}")
            raise
    
    def get_online_features(self, machine_ids: list) -> pd.DataFrame:
        """
        R√©cup√®re les 13 features online pour des machines sp√©cifiques
        
        Args:
            machine_ids: Liste des IDs de machines
            
        Returns:
            DataFrame avec les 13 features
        """
        try:
            entity_rows = [{"machine_id": mid} for mid in machine_ids]
            
            feature_vector = self.store.get_online_features(
                features=[
                    "machine_audio_features:rms_mean",
                    "machine_audio_features:rms_std",
                    "machine_audio_features:zcr_mean",
                    "machine_audio_features:spectral_centroid",
                    "machine_audio_features:spectral_bandwidth",
                    "machine_audio_features:spectral_rolloff",
                    "machine_audio_features:spectral_contrast",
                    "machine_audio_features:mfcc_0",
                    "machine_audio_features:mfcc_1",
                    "machine_audio_features:mfcc_2",
                    "machine_audio_features:mfcc_3",
                    "machine_audio_features:mfcc_4",
                    "machine_audio_features:mfcc_5",
                ],
                entity_rows=entity_rows
            ).to_df()
            
            return feature_vector
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des features online: {e}")
            raise
    
    def get_historical_features(
        self,
        entity_df: pd.DataFrame,
        features: list = None
    ) -> pd.DataFrame:
        """
        R√©cup√®re les 13 features historiques pour l'entra√Ænement
        
        Args:
            entity_df: DataFrame avec machine_id et event_timestamp
            features: Liste des features √† r√©cup√©rer (None = toutes les 13)
            
        Returns:
            DataFrame avec les features historiques
        """
        try:
            if features is None:
                features = [
                    "machine_audio_features:rms_mean",
                    "machine_audio_features:rms_std",
                    "machine_audio_features:zcr_mean",
                    "machine_audio_features:spectral_centroid",
                    "machine_audio_features:spectral_bandwidth",
                    "machine_audio_features:spectral_rolloff",
                    "machine_audio_features:spectral_contrast",
                    "machine_audio_features:mfcc_0",
                    "machine_audio_features:mfcc_1",
                    "machine_audio_features:mfcc_2",
                    "machine_audio_features:mfcc_3",
                    "machine_audio_features:mfcc_4",
                    "machine_audio_features:mfcc_5",
                ]
            
            training_df = self.store.get_historical_features(
                entity_df=entity_df,
                features=features
            ).to_df()
            
            return training_df
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des features historiques: {e}")
            raise


# ================================
# Script d'initialisation Feast
# ================================

def setup_feast():
    """
    Configure et initialise Feast avec PostgreSQL
    """
    import subprocess
    import os
    from pathlib import Path
    
    feast_dir = Path("./mlops/feature_store/feast_config")
    feast_dir.mkdir(exist_ok=True)
    
    # Changer vers le dossier feast
    os.chdir(feast_dir)
    
    print("üì¶ Initialisation du projet Feast...")
    
    # Apply des d√©finitions de features
    try:
        subprocess.run(["feast", "apply"], check=True)
        print("‚úì Features enregistr√©es dans le registry")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Erreur lors de feast apply: {e}")
        return False
    
    os.chdir("..")
    return True


def materialize_initial_features():
    """
    Mat√©rialise les features initiales dans le online store
    """
    from datetime import datetime, timedelta
    import pandas as pd
    
    manager = FeastFeatureManager()
    
    # Lire les donn√©es pour obtenir la vraie plage de dates
    df = pd.read_parquet("./features/normal_features.parquet")
    
    # Utiliser les vraies dates min/max des donn√©es
    start_date = df['event_timestamp'].min()
    end_date = df['event_timestamp'].max() + timedelta(hours=1)
    
    print(f"\nüìä Mat√©rialisation des features...")
    print(f"   P√©riode r√©elle des donn√©es: {start_date} -> {end_date}")
    print(f"   Nombre d'enregistrements: {len(df)}")
    
    manager.materialize_features(start_date, end_date)
    print("‚úì Features mat√©rialis√©es dans le online store")


def test_feature_retrieval():
    """
    Test de r√©cup√©ration des features avec v√©rification
    """
    import pandas as pd
    manager = FeastFeatureManager()
    
    # Charger les donn√©es pour obtenir des machine_ids
    df = pd.read_parquet("./features/normal_features.parquet")
    sample_machines = df['machine_id'].head(3).tolist()
    
    print(f"\nüîç Test de r√©cup√©ration des features pour: {sample_machines}")
    
    # R√©cup√©rer les features online
    features_df = manager.get_online_features(sample_machines)
    print("\n‚úì Features online r√©cup√©r√©es:")
    print(features_df)
    
    # V√©rifier si les valeurs sont None
    null_count = features_df.isnull().sum().sum()
    total_values = features_df.shape[0] * (features_df.shape[1] - 1)  # -1 pour machine_id
    
    if null_count == total_values:
        print("\n‚ö†Ô∏è  ATTENTION: Toutes les features online sont NULL!")
        print("   Causes possibles:")
        print("   1. La p√©riode de mat√©rialisation ne correspond pas aux timestamps")
        print("   2. Les machine_id ne matchent pas")
        print("   3. Probl√®me de connexion PostgreSQL")
        
        # V√©rifier dans PostgreSQL
        print("\nüîç V√©rification dans PostgreSQL...")
        check_postgres_data()
    else:
        print(f"\n‚úÖ {total_values - null_count}/{total_values} valeurs r√©cup√©r√©es avec succ√®s")
    
    # R√©cup√©rer les features historiques
    entity_df = df[['machine_id', 'event_timestamp']].head(5)
    historical_df = manager.get_historical_features(entity_df)
    print("\n‚úì Features historiques r√©cup√©r√©es:")
    print(historical_df.head())


def check_postgres_data():
    """
    V√©rifie directement les donn√©es dans PostgreSQL
    """
    try:
        import psycopg2
        import pandas as pd
        from sqlalchemy import create_engine
        
        # Configuration PostgreSQL
        conn_string = "postgresql://postgres:Chiheb12345@localhost:5432/feast_online"
        
        engine = create_engine(conn_string)
        
        # Lister les tables
        query = """
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public'
        ORDER BY table_name
        """
        tables = pd.read_sql(query, engine)
        print(f"\nüìã Tables disponibles dans feast_online:")
        for table in tables['table_name'].tolist():
            print(f"   - {table}")
        
        # Chercher la table des features (le nom peut varier)
        feature_tables = [t for t in tables['table_name'].tolist() if 'machine_audio' in t.lower() or 'mlops' in t.lower()]
        
        if feature_tables:
            for table in feature_tables:
                print(f"\nüìä Table: {table}")
                count_query = f"SELECT COUNT(*) as count FROM {table}"
                count_df = pd.read_sql(count_query, engine)
                print(f"   Enregistrements: {count_df['count'].iloc[0]}")
                
                # Afficher quelques lignes
                sample_query = f"SELECT * FROM {table} LIMIT 5"
                sample_df = pd.read_sql(sample_query, engine)
                print(f"\n   Colonnes: {sample_df.columns.tolist()}")
                print(f"\n   √âchantillon:")
                print(sample_df)
        else:
            print("\n‚ö†Ô∏è  Aucune table de features trouv√©e!")
            print("   Tables disponibles:", tables['table_name'].tolist())
        
        engine.dispose()
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification PostgreSQL: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("=" * 60)
    print("Configuration Feast pour D√©tection d'Anomalies")
    print("=" * 60)
    
    # √âtape 1: Setup Feast
    if setup_feast():
        print("\n‚úì Feast configur√© avec succ√®s")
        
        # √âtape 2: Mat√©rialiser les features
        materialize_initial_features()
        
        # √âtape 3: Test de r√©cup√©ration
        test_feature_retrieval()
        
        print("\n" + "=" * 60)
        print("‚úÖ Configuration termin√©e avec succ√®s!")
        print("=" * 60)
    else:
        print("\n‚ùå Erreur lors de la configuration")