# ğŸ”§ DÃ©tection d'Anomalies dans les Machines - Projet MLOps

SystÃ¨me de dÃ©tection d'anomalies en temps rÃ©el basÃ© sur l'analyse des vibrations de machines industrielles utilisant des techniques d'apprentissage profond non supervisÃ©.

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'Ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Installation](#installation)
- [Partie 1 : Feature Engineering & Feature Store](#partie-1--feature-engineering--feature-store)
- [Partie 2 : Training & MLflow](#partie-2--training--mlflow)
- [Structure du Projet](#structure-du-projet)
- [Utilisation](#utilisation)
- [Configuration](#configuration)
- [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Vue d'Ensemble

Ce projet implÃ©mente un pipeline MLOps complet pour la dÃ©tection d'anomalies dans les machines industrielles Ã  partir de signaux audio de vibrations.

### Approche Technique

- **MÃ©thode** : Apprentissage non supervisÃ© (Autoencoder)
- **Features** : Spectrogrammes Mel + Features statistiques
- **Feature Store** : Feast avec PostgreSQL
- **Training** : PyTorch Lightning + MLflow
- **DÃ©tection** : Erreur de reconstruction > seuil

### Cas d'Usage

âœ… Maintenance prÃ©dictive  
âœ… DÃ©tection de pannes  
âœ… Surveillance en temps rÃ©el  
âœ… RÃ©duction des temps d'arrÃªt  

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE MLOPS COMPLET                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. DATA INGESTION   â”‚
â”‚  Fichiers Audio .wav â”‚
â”‚  Vibrations machines â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. FEATURE ENGINEERING                                      â”‚
â”‚                                                              â”‚
â”‚  A. Spectrogrammes Mel (128 bandes)                         â”‚
â”‚     â†’ SauvegardÃ©s en .npy pour training                     â”‚
â”‚                                                              â”‚
â”‚  B. 13 Features Statistiques                                â”‚
â”‚     â†’ rms_mean, spectral_centroid, mfcc_0-5, etc.          â”‚
â”‚     â†’ SauvegardÃ©s en Parquet                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. FEATURE STORE (FEAST + POSTGRESQL)                       â”‚
â”‚                                                              â”‚
â”‚  Offline Store (Parquet)     Online Store (PostgreSQL)      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ DonnÃ©es historiquesâ”‚  â•â•â–º  â”‚ Latence < 10ms   â”‚          â”‚
â”‚  â”‚ Pour training     â”‚ MatÃ©r.â”‚ Pour production  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. MODEL TRAINING (CNN AUTOENCODER)                         â”‚
â”‚                                                              â”‚
â”‚  PyTorch Lightning + MLflow                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚Encoder â”‚ â†’ â”‚  Latent  â”‚ â†’ â”‚Decoder â”‚                    â”‚
â”‚  â”‚        â”‚   â”‚  Space   â”‚   â”‚        â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                              â”‚
â”‚  Loss: MSE(input, reconstruction)                            â”‚
â”‚  MÃ©triques: AUC, F1, Recall, Precision                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. MODEL REGISTRY (MLFLOW)                                  â”‚
â”‚                                                              â”‚
â”‚  PostgreSQL Backend                                          â”‚
â”‚  â”œâ”€ Experiments tracking                                     â”‚
â”‚  â”œâ”€ Hyperparameters logging                                  â”‚
â”‚  â”œâ”€ Metrics comparison                                       â”‚
â”‚  â””â”€ Model versioning                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. INFERENCE (TEMPS RÃ‰EL)                                   â”‚
â”‚                                                              â”‚
â”‚  Nouveau signal â†’ Features â†’ Feast â†’ Model â†’ Anomalie?      â”‚
â”‚                      (< 10ms)         (< 50ms)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Installation

### PrÃ©requis

- Python 3.10+
- PostgreSQL 12+
- 8GB RAM minimum
- GPU recommandÃ© (optionnel)

### 1. Cloner le Repository

```bash
git clone <votre-repo>
cd mlops
```

### 2. CrÃ©er l'Environnement Virtuel

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Installer les DÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Configurer PostgreSQL

```sql
-- Se connecter Ã  PostgreSQL
psql -U postgres

-- CrÃ©er les bases de donnÃ©es
CREATE DATABASE feast_online;
CREATE DATABASE mlflow_db;

-- VÃ©rifier
\l
```

---

## ğŸ“¦ Partie 1 : Feature Engineering & Feature Store

### Objectif

Extraire les features audio et les stocker dans un Feature Store pour un accÃ¨s rapide.

### 1.1 Feature Engineering

**Script** : `mlops/feature_store/feature_engineering.py`

**Ce qu'il fait** :
- Lit les fichiers audio normaux (`data/normal/*.wav`)
- Extrait des spectrogrammes Mel (128 bandes)
- Calcule 13 features statistiques
- Sauvegarde tout dans `mlops/feature_store/features/`

**ExÃ©cution** :

```bash
# Placer vos fichiers audio dans data/normal/
python mlops/feature_store/feature_engineering.py
```

**Output** :
```
features/
â”œâ”€â”€ normal_spectrograms.npy    # (N, 128, temps) pour l'autoencoder
â”œâ”€â”€ normal_features.parquet    # 13 features pour Feast
â””â”€â”€ normal_features.csv        # Backup
```

### 1.2 Configuration Feast

**Script** : `mlops/feature_store/feast_config/features.py`

**Configuration** : `mlops/feature_store/feast_config/feature_store.yaml`

```yaml
project: mlops
registry: registry.db
provider: local

online_store:
  type: postgres
  host: localhost
  port: 5432
  database: feast_online
  user: postgres
  password: VOTRE_PASSWORD

offline_store:
  type: file
```

**Initialisation** :

```bash
cd mlops/feature_store/feast_config
feast apply
cd ../../..
```

### 1.3 MatÃ©rialisation des Features

**Script** : `mlops/feature_store/feast_operations.py`

```bash
python mlops/feature_store/feast_operations.py
```

**RÃ©sultat** :
- 13 features Ã— N machines dans PostgreSQL (online store)
- Accessibles en < 10ms pour l'infÃ©rence

### 1.4 Les 13 Features

| # | Feature | Description |
|---|---------|-------------|
| 1-2 | `rms_mean`, `rms_std` | Ã‰nergie du signal |
| 3 | `zcr_mean` | Taux de passage par zÃ©ro |
| 4 | `spectral_centroid` | Centre de masse spectral |
| 5 | `spectral_bandwidth` | Largeur de bande |
| 6 | `spectral_rolloff` | Concentration d'Ã©nergie |
| 7 | `spectral_contrast` | Contraste spectral |
| 8-13 | `mfcc_0` Ã  `mfcc_5` | Coefficients MFCC |

### 1.5 Utilisation du Feature Store

```python
from feast import FeatureStore

store = FeatureStore(repo_path="./mlops/feature_store/feast_config")

# Online features (temps rÃ©el)
features = store.get_online_features(
    features=["machine_audio_features:rms_mean", ...],
    entity_rows=[{"machine_id": "machine_001"}]
).to_df()

# Historical features (training)
historical = store.get_historical_features(
    entity_df=entity_df,
    features=[...]
).to_df()
```

---

## ğŸ¤– Partie 2 : Training & MLflow

### Objectif

EntraÃ®ner un CNN Autoencoder pour apprendre les patterns normaux et dÃ©tecter les anomalies.

### 2.1 Configuration MLflow

**Script** : `mlops/training/mlflow_config.py`

```bash
# CrÃ©er la base de donnÃ©es MLflow
python mlops/training/mlflow_config.py
```

### 2.2 PrÃ©paration des DonnÃ©es de Test

**Structure requise** :

```
data/test/
â”œâ”€â”€ normal_001.wav
â”œâ”€â”€ normal_002.wav
â”œâ”€â”€ anomaly_001.wav
â”œâ”€â”€ anomaly_002.wav
â””â”€â”€ ...
```

**Important** : Les fichiers doivent contenir "normal" ou "anomaly" dans leur nom pour la dÃ©tection automatique des labels.

### 2.3 EntraÃ®nement

**Script** : `mlops/training/train.py`

```bash
# Test rapide (1 epoch)
python mlops/training/train.py

# Production (50 epochs)
# Modifier max_epochs=50 dans train.py
```

**HyperparamÃ¨tres configurables** :

```python
train_model(
    z_dim=40,                    # Dimension du latent space
    learning_rate=1e-3,          # Learning rate
    threshold_percentile=95.0,   # Seuil de dÃ©tection (95Ã¨me percentile)
    max_epochs=50,               # Nombre d'epochs
    batch_size=32,               # Taille des batchs
    accelerator="auto",          # "gpu" ou "cpu"
)
```

### 2.4 Architecture du ModÃ¨le

```
Input: (batch, 1, 128, temps)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Encoder             â”‚
â”‚ Conv2D(1â†’32)        â”‚
â”‚ Conv2D(32â†’64)       â”‚
â”‚ Conv2D(64â†’128)      â”‚
â”‚ Conv2D(128â†’256)     â”‚
â”‚ Conv2D(256â†’z_dim)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    [Latent Space]
    (compressed)
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Decoder             â”‚
â”‚ ConvT2D(z_dimâ†’256)  â”‚
â”‚ ConvT2D(256â†’128)    â”‚
â”‚ ConvT2D(128â†’64)     â”‚
â”‚ ConvT2D(64â†’32)      â”‚
â”‚ ConvT2D(32â†’1)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output: (batch, 1, 128, temps)
```

### 2.5 MÃ©triques TrackÃ©es

**Pendant Training** :
- `train_loss` : MSE de reconstruction
- `val_loss` : Loss sur test set
- `threshold` : Seuil calculÃ©

**Test Final** :
- **AUC** : Area Under ROC Curve (0-1)
- **F1 Score** : Balance Precision/Recall
- **Recall** : Taux de dÃ©tection des anomalies
- **Precision** : Taux de vraies dÃ©tections
- **Accuracy** : PrÃ©cision globale
- Confusion Matrix (TP, FP, TN, FN)

### 2.6 MLflow UI

```bash
mlflow ui --backend-store-uri postgresql://postgres:PASSWORD@localhost:5432/mlflow_db
```

Ouvrir : **http://localhost:5000**

**FonctionnalitÃ©s** :
- ğŸ“Š Comparaison des runs
- ğŸ“ˆ Visualisation des mÃ©triques
- ğŸ” Recherche par hyperparamÃ¨tres
- ğŸ’¾ Model Registry
- ğŸ·ï¸ Tagging et versioning

### 2.7 Principe de DÃ©tection

```python
# DonnÃ©es normales â†’ Faible erreur de reconstruction
error_normal = MSE(input, autoencoder(input))  # ~ 0.01

# DonnÃ©es anormales â†’ Forte erreur de reconstruction  
error_anomaly = MSE(input, autoencoder(input))  # ~ 0.05

# DÃ©cision
if error > threshold:
    prediction = "ANOMALY" ğŸš¨
else:
    prediction = "NORMAL" âœ…
```

---

## ğŸ“‚ Structure du Projet

```
mlops/
â”œâ”€â”€ feature_store/
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ normal_spectrograms.npy      # Spectrogrammes pour training
â”‚   â”‚   â”œâ”€â”€ normal_features.parquet      # Features pour Feast
â”‚   â”‚   â””â”€â”€ normal_features.csv
â”‚   â”œâ”€â”€ feast_config/
â”‚   â”‚   â”œâ”€â”€ feature_store.yaml           # Config Feast
â”‚   â”‚   â”œâ”€â”€ features.py                  # DÃ©finition des features
â”‚   â”‚   â””â”€â”€ registry.db                  # Registry SQLite
â”‚   â”œâ”€â”€ feature_engineering.py           # Extraction features
â”‚   â””â”€â”€ feast_operations.py              # OpÃ©rations Feast
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ mlflow_config.py                 # Configuration MLflow
â”‚   â”œâ”€â”€ dataset.py                       # Dataset PyTorch
â”‚   â”œâ”€â”€ model.py                         # CNN Autoencoder
â”‚   â””â”€â”€ train.py                         # Script training
data/
â”œâ”€â”€ normal/                              # Fichiers audio normaux (training)
â”‚   â”œâ”€â”€ normal_001.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ test/                                # Fichiers audio test (normal + anomaly)
    â”œâ”€â”€ normal_test_001.wav
    â”œâ”€â”€ anomaly_test_001.wav
    â””â”€â”€ ...
checkpoints/                             # Checkpoints PyTorch Lightning
mlruns/                                  # Artifacts MLflow
requirements.txt                         # DÃ©pendances Python
README.md                                # Ce fichier
```

---

## ğŸš€ Utilisation

### Workflow Complet

```bash
# 1. Feature Engineering
python mlops/feature_store/feature_engineering.py

# 2. Configuration Feast
cd mlops/feature_store/feast_config
feast apply
cd ../../..

# 3. MatÃ©rialisation
python mlops/feature_store/feast_operations.py

# 4. Configuration MLflow
python mlops/training/mlflow_config.py

# 5. Training (test rapide)
python mlops/training/train.py

# 6. MLflow UI
mlflow ui --backend-store-uri postgresql://postgres:PASSWORD@localhost:5432/mlflow_db
```

### Test d'InfÃ©rence

```python
import torch
from mlops.training.model import LitAutoEncoder

# Charger le modÃ¨le
model = LitAutoEncoder.load_from_checkpoint("checkpoints/best.ckpt")
model.eval()

# PrÃ©dire
with torch.no_grad():
    is_anomaly, error = model.predict_anomaly(spectrogram_tensor)
    
print(f"Anomalie: {is_anomaly}, Erreur: {error:.4f}")
```

---

## âš™ï¸ Configuration

### PostgreSQL

**Modifier les mots de passe** :

1. `mlops/feature_store/feast_config/feature_store.yaml`
2. `mlops/training/mlflow_config.py`

### HyperparamÃ¨tres

**Fichier** : `mlops/training/train.py`

```python
# Ajuster selon vos besoins
z_dim = 40                      # Compression (20-60)
learning_rate = 1e-3            # LR (1e-4 Ã  1e-2)
threshold_percentile = 95.0     # SensibilitÃ© (90-99)
max_epochs = 50                 # DurÃ©e training
batch_size = 32                 # Selon RAM/GPU
```

---

## ğŸ› Troubleshooting

### Erreur : "Cannot connect to PostgreSQL"

```bash
# VÃ©rifier que PostgreSQL est lancÃ©
# Windows: Services â†’ PostgreSQL â†’ DÃ©marrer

# Tester la connexion
psql -U postgres -h localhost
```

### Erreur : "CUDA out of memory"

```python
# RÃ©duire batch_size
train_model(batch_size=16)

# Ou forcer CPU
train_model(accelerator="cpu")
```

### Erreur : "No audio files found"

```bash
# VÃ©rifier la structure
ls data/normal/
ls data/test/

# Extensions supportÃ©es: .wav, .mp3, .flac, .ogg
```

### Erreur : "Cannot determine label"

Les fichiers dans `data/test/` doivent contenir "normal" ou "anomaly" dans leur nom :
- âœ… `normal_001.wav`
- âœ… `test_anomaly_005.wav`
- âŒ `file_001.wav` (pas de label clair)

### Performance faible

- **AUC < 0.7** : Augmenter epochs, ajuster learning_rate
- **F1 < 0.6** : VÃ©rifier quality des donnÃ©es, ajuster threshold
- **Trop de faux positifs** : Augmenter threshold_percentile (ex: 97)
- **Anomalies manquÃ©es** : Diminuer threshold_percentile (ex: 90)

---

## ğŸ“Š Exemples de RÃ©sultats

### Training RÃ©ussi

```
Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [02:30<00:00]
train_loss: 0.0189
val_loss: 0.0234
threshold: 0.0312

Test Metrics:
- AUC: 0.9245
- F1 Score: 0.8567
- Recall: 0.8900
- Precision: 0.8260
- Accuracy: 0.8750
```

### InterprÃ©tation

- **AUC > 0.9** : Excellente sÃ©paration normal/anomaly âœ…
- **F1 > 0.85** : Bon Ã©quilibre dÃ©tection/prÃ©cision âœ…
- **Recall 89%** : 89% des anomalies dÃ©tectÃ©es âœ…
- **Precision 82%** : 82% des alertes sont vraies âœ…

---

## ğŸ”® Prochaines Ã‰tapes

- [ ] API FastAPI pour infÃ©rence temps rÃ©el
- [ ] Dashboard de monitoring (Grafana)
- [ ] Pipeline CI/CD (GitHub Actions)
- [ ] DÃ©tection de drift
- [ ] Retraining automatique
- [ ] DÃ©ploiement Docker/Kubernetes

---

## ğŸ“š Ressources

- [Feast Documentation](https://docs.feast.dev/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/)
- [Librosa Audio Processing](https://librosa.org/)

---

## ğŸ‘¥ Auteurs

Projet MLOps - DÃ©tection d'Anomalies dans les Machines Industrielles

---

## ğŸ“„ License

[Votre License]

---

**ğŸ¯ Happy Anomaly Hunting! ğŸ”§**